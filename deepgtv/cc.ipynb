{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from dgtv.dgtv import *\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python train_gtv.py --batch 1 --lr 1e-3 --umin 0.01 --umax 100 -m model/GTV.pkl --epoch 5 --train dataset/dataset_structure --width 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supporting_matrix(opt):\n",
    "    dtype = opt.dtype\n",
    "    cuda = opt.cuda\n",
    "    width = opt.width\n",
    "\n",
    "    pixel_indices = [i for i in range(width * width)]\n",
    "    pixel_indices = np.reshape(pixel_indices, (width, width))\n",
    "    A = connected_adjacency(pixel_indices, connect=opt.connectivity)\n",
    "    A_pair = np.asarray(np.where(A.toarray() == 1)).T\n",
    "    A_pair = np.unique(np.sort(A_pair, axis=1), axis=0)\n",
    "\n",
    "    opt.edges = A_pair.shape[0]\n",
    "    H_dim0 = opt.edges\n",
    "    H_dim1 = width ** 2\n",
    "\n",
    "    I = torch.eye(width ** 2, width ** 2).type(dtype)\n",
    "    A = torch.zeros(width ** 2, width ** 2).type(dtype)\n",
    "    H = torch.zeros(H_dim0, H_dim1).type(dtype)\n",
    "    for e, p in enumerate(A_pair):\n",
    "        H[e, p[0]] = 1\n",
    "        H[e, p[1]] = -1\n",
    "        A[p[0], p[1]] = 1\n",
    "\n",
    "    opt.I = I\n",
    "    opt.pairs = A_pair\n",
    "    opt.H = H\n",
    "    opt.connectivity_full = A.requires_grad_(True)\n",
    "    opt.connectivity_idx = torch.where(A > 0)\n",
    "\n",
    "    for e, p in enumerate(A_pair):\n",
    "        A_temp = A.clone()\n",
    "        A_temp[p[1], p[0]] = 1\n",
    "        A = A_temp\n",
    "    opt.logger.info(\"OPT created on cuda: {0} {1}\".format(cuda, dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    seed, model_name, cont=None, optim_name=None, subset=None, epoch=100, args=None\n",
    "):\n",
    "    cuda = True if torch.cuda.is_available() else False\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    opt.logger.info(\"CUDA: {0}\".format(cuda))\n",
    "    if cuda:\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "        opt.logger.info(torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    DST = \"./\"\n",
    "    DST = \"\"\n",
    "    PATH = os.path.join(DST, model_name)\n",
    "    SAVEPATH = PATH.split(\".\")[-1]\n",
    "    SAVEDIR = \"\".join(PATH.split(\".\")[:-1]) + \"_\"\n",
    "    batch_size = opt.batch_size\n",
    "    if not subset:\n",
    "        _subset = [\"10\", \"1\", \"7\", \"8\", \"9\"]\n",
    "        # _subset = [\"1\", \"3\", \"5\", \"7\", \"9\"]\n",
    "        opt.logger.info(\"Train: {0}\".format(_subset))\n",
    "        subset = [i + \"_\" for i in _subset]\n",
    "    else:\n",
    "        subset = [i + \"_\" for i in subset]\n",
    "    dataset = RENOIR_Dataset(\n",
    "        img_dir=os.path.join(opt.train),\n",
    "        transform=transforms.Compose(\n",
    "            [standardize(normalize=False), ToTensor()]),\n",
    "        subset=None,\n",
    "    )\n",
    "    opt.logger.info(\"Splitting patches...\")\n",
    "    patch_splitting(\n",
    "        dataset=dataset, output_dst=\"tmp\", patch_size=args.width, stride=args.width / 2\n",
    "    )\n",
    "    dataset = RENOIR_Dataset(\n",
    "        img_dir=os.path.join(\"tmp\", \"patches\"),\n",
    "        transform=transforms.Compose(\n",
    "            [standardize(normalize=False), ToTensor()]),\n",
    "        subset=subset,\n",
    "    )\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=4,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    supporting_matrix(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supporting_matrix(opt):\n",
    "    dtype = opt.dtype\n",
    "    cuda = opt.cuda\n",
    "    width = opt.width\n",
    "\n",
    "    pixel_indices = [i for i in range(width * width)]\n",
    "    pixel_indices = np.reshape(pixel_indices, (width, width))\n",
    "    A = connected_adjacency(pixel_indices, connect=opt.connectivity)\n",
    "    A_pair = np.asarray(np.where(A.toarray() == 1)).T\n",
    "    A_pair = np.unique(np.sort(A_pair, axis=1), axis=0)\n",
    "\n",
    "    opt.edges = A_pair.shape[0]\n",
    "    H_dim0 = opt.edges\n",
    "    H_dim1 = width ** 2\n",
    "\n",
    "    I = torch.eye(width ** 2, width ** 2).type(dtype)\n",
    "    A = torch.zeros(width ** 2, width ** 2).type(dtype)\n",
    "    H = torch.zeros(H_dim0, H_dim1).type(dtype)\n",
    "    for e, p in enumerate(A_pair):\n",
    "        H[e, p[0]] = 1\n",
    "        H[e, p[1]] = -1\n",
    "        A[p[0], p[1]] = 1\n",
    "\n",
    "    opt.I = I\n",
    "    opt.pairs = A_pair\n",
    "    opt.H = H\n",
    "    opt.connectivity_full = A.requires_grad_(True)\n",
    "    opt.connectivity_idx = torch.where(A > 0)\n",
    "\n",
    "    for e, p in enumerate(A_pair):\n",
    "        A_temp = A.clone()\n",
    "        A_temp[p[1], p[0]] = 1\n",
    "        A = A_temp\n",
    "    opt.logger.info(\"OPT created on cuda: {0} {1}\".format(cuda, dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Đoạn code để tạo một tập dữ liệu giả định từ GTV\n",
    "# Đảm bảo rằng data_features và data_labels được xây dựng từ đặc trưng GTV và nhãn tương ứng.\n",
    "\n",
    "# Xác định đặc trưng và nhãn từ dữ liệu GTV sử dụng supporting_matrix(opt)\n",
    "opt = ...  # Đối tượng opt được sử dụng để gọi supporting_matrix(opt)\n",
    "data_features = supporting_matrix(opt)  # Dùng hàm supporting_matrix để trích xuất đặc trưng\n",
    "data_labels = [...]  # Nhãn tương ứng\n",
    "\n",
    "# Chia tập dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_features, data_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Xây dựng mô hình KNN với K=3 (có thể điều chỉnh K theo nhu cầu)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán nhãn của dữ liệu kiểm tra\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Đánh giá hiệu suất của mô hình KNN\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as ss\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnnf_2(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(cnnf_2, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(opt.channels, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 6, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class uu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(uu,self).__init__()\n",
    "        self.u = torch.nn.Parameter(torch.rand(1), requires_grad=True)\n",
    "    def forward(self):\n",
    "        return self.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnnu(nn.Module):\n",
    "    \"\"\"\n",
    "    CNNU of GLR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, u_min=1e-3, opt=None):\n",
    "        super(cnnu, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(opt.channels, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n",
    "        )\n",
    "\n",
    "        self.opt = opt\n",
    "        self.u_min = u_min\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.linear_input_neurons(), 1 * 1 * 32),\n",
    "            nn.Linear(1 * 1 * 32, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    def size_after_relu(self, x):\n",
    "        x = self.layer(x)\n",
    "\n",
    "        return x.size()\n",
    "\n",
    "    def linear_input_neurons(self):\n",
    "        size = self.size_after_relu(\n",
    "            torch.rand(1, self.opt.channels, self.opt.width, self.opt.width)\n",
    "        )\n",
    "        m = 1\n",
    "        for i in size:\n",
    "            m *= i\n",
    "\n",
    "        return int(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as ss\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnnf_2(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(cnnf_2, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(opt.channels, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 6, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class uu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(uu,self).__init__()\n",
    "        self.u = torch.nn.Parameter(torch.rand(1), requires_grad=True)\n",
    "    def forward(self):\n",
    "        return self.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lá»›p cnnu\n",
    "class cnnu(nn.Module):\n",
    "    \"\"\"\n",
    "    CNNU of GLR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, u_min=1e-3, opt=None):\n",
    "        super(cnnu, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(opt.channels, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n",
    "        )\n",
    "\n",
    "        self.opt = opt\n",
    "        self.u_min = u_min\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.linear_input_neurons(), 1 * 1 * 32),\n",
    "            nn.Linear(1 * 1 * 32, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    def size_after_relu(self, x):\n",
    "        x = self.layer(x)\n",
    "\n",
    "        return x.size()\n",
    "\n",
    "    def linear_input_neurons(self):\n",
    "        size = self.size_after_relu(\n",
    "            torch.rand(1, self.opt.channels, self.opt.width, self.opt.width)\n",
    "        )\n",
    "        m = 1\n",
    "        for i in size:\n",
    "            m *= i\n",
    "\n",
    "        return int(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RENOIR_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset loader\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_dir, transform=None, subset=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_dir (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.npath = os.path.join(img_dir, \"noisy\")\n",
    "        self.rpath = os.path.join(img_dir, \"ref\")\n",
    "        self.subset = subset\n",
    "        self.nimg_name = sorted(os.listdir(self.npath))\n",
    "        self.rimg_name = sorted(os.listdir(self.rpath))\n",
    "        self.nimg_name = [\n",
    "            i\n",
    "            for i in self.nimg_name\n",
    "            if i.split(\".\")[-1].lower() in [\"jpeg\", \"jpg\", \"png\", \"bmp\", \"tif\"]\n",
    "        ]\n",
    "\n",
    "        self.rimg_name = [\n",
    "            i\n",
    "            for i in self.rimg_name\n",
    "            if i.split(\".\")[-1].lower() in [\"jpeg\", \"jpg\", \"png\", \"bmp\", \"tif\"]\n",
    "        ]\n",
    "\n",
    "        if self.subset:\n",
    "            nimg_name = list()\n",
    "            rimg_name = list()\n",
    "            for i in range(len(self.nimg_name)):\n",
    "                for j in self.subset:\n",
    "                    if j in self.nimg_name[i]:\n",
    "                        nimg_name.append(self.nimg_name[i])\n",
    "                        # if j in self.rimg_name[i]:\n",
    "                        rimg_name.append(self.rimg_name[i])\n",
    "            self.nimg_name = sorted(nimg_name)\n",
    "            self.rimg_name = sorted(rimg_name)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nimg_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        uid = np.random.randint(0, 8)  # augment type\n",
    "        # uid = 0\n",
    "        nimg_name = os.path.join(self.npath, self.nimg_name[idx])\n",
    "        nimg = cv2.imread(nimg_name)\n",
    "        nimg = data_aug(nimg, uid)\n",
    "        rimg_name = os.path.join(self.rpath, self.rimg_name[idx])\n",
    "        rimg = cv2.imread(rimg_name)\n",
    "        rimg = data_aug(rimg, uid)\n",
    "\n",
    "        sample = {\"nimg\": nimg, \"rimg\": rimg}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tien xu li du lieu hinh anh \n",
    "##\n",
    "class standardize(object):\n",
    "    # \"\"\"Convert opencv BGR to RGB order. Scale the image with a ratio\"\"\"\n",
    "    \"\"\"Convert opencv BGR to gray order. Scale the image with a ratio\"\"\"\n",
    "\n",
    "    def __init__(self, scale=None, w=None, normalize=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        scale (float): resize height and width of samples to scale*width and scale*height\n",
    "        width (float): resize height and width of samples to width x width. Only works if \"scale\" is not specified\n",
    "        \"\"\"\n",
    "        self.scale = scale\n",
    "        self.w = w\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        nimg, rimg = sample[\"nimg\"], sample[\"rimg\"]\n",
    "        if self.scale:\n",
    "            nimg = cv2.resize(nimg, (0, 0), fx=self.scale, fy=self.scale)\n",
    "            rimg = cv2.resize(rimg, (0, 0), fx=self.scale, fy=self.scale)\n",
    "        else:\n",
    "            if self.w:\n",
    "                nimg = cv2.resize(nimg, (self.w, self.w))\n",
    "                rimg = cv2.resize(rimg, (self.w, self.w))\n",
    "        if self.normalize:\n",
    "            nimg = cv2.resize(nimg, (0, 0), fx=1, fy=1)\n",
    "            rimg = cv2.resize(rimg, (0, 0), fx=1, fy=1)\n",
    "        # nimg = cv2.cvtColor(nimg, cv2.COLOR_BGR2RGB)\n",
    "        # rimg = cv2.cvtColor(rimg, cv2.COLOR_BGR2RGB)\n",
    "        nimg = cv2.cvtColor(nimg, cv2.COLOR_BGR2GRAY)\n",
    "        nimg = np.expand_dims(nimg, axis=2)\n",
    "        rimg = cv2.cvtColor(rimg, cv2.COLOR_BGR2GRAY)\n",
    "        rimg = np.expand_dims(rimg, axis=2)\n",
    "        \n",
    "        if self.normalize:\n",
    "            nimg = nimg / 255.0\n",
    "            rimg = rimg / 255.0\n",
    "        return {\"nimg\": nimg, \"rimg\": rimg}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
